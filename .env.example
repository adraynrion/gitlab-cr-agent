# Environment
ENVIRONMENT=development
DEBUG=False
LOG_LEVEL=INFO
PORT=8000

# Rate Limiting (Global for single GitLab instance)
RATE_LIMIT_ENABLED=true
GLOBAL_RATE_LIMIT=100/minute
WEBHOOK_RATE_LIMIT=10/minute

# GitLab Configuration
GITLAB_URL=https://gitlab.example.com
GITLAB_TOKEN=your_gitlab_personal_access_token
GITLAB_WEBHOOK_SECRET=your_webhook_secret_token
GITLAB_TRIGGER_TAG=ai-review

# AI Model Selection (options: openai:gpt-4o, anthropic:claude-3-5-sonnet, gemini:gemini-2.5-pro, fallback)
AI_MODEL=openai:gpt-4o
AI_TEMPERATURE=0.3
AI_MAX_TOKENS=4000
AI_RETRIES=3

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key
OPENAI_MODEL_NAME=gpt-4o
# OPENAI_BASE_URL=https://api.openai.com  # Optional: Custom OpenAI-compatible API endpoint

# Anthropic Configuration (optional)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key
ANTHROPIC_MODEL_NAME=claude-3-5-sonnet-latest
# ANTHROPIC_BASE_URL=https://api.anthropic.com  # Optional: Custom Anthropic-compatible API endpoint

# Google Configuration (optional)
GOOGLE_API_KEY=your-google-api-key
GEMINI_MODEL_NAME=gemini-2.5-pro
# GOOGLE_BASE_URL=https://generativelanguage.googleapis.com  # Optional: Custom Google-compatible API endpoint

# Security & Performance
# MAX_REQUEST_SIZE in bytes (default: 10MB)
MAX_REQUEST_SIZE=10485760
# MAX_DIFF_SIZE in bytes (default: 1MB) - Maximum diff content size for processing
MAX_DIFF_SIZE=1048576
# Optional API authentication
API_KEY=your-internal-api-key
ALLOWED_ORIGINS=["https://gitlab.example.com"]

# HTTP Client Configuration
# Request timeout in seconds
REQUEST_TIMEOUT=30.0
# Maximum concurrent connections
MAX_CONNECTIONS=100
# Maximum keepalive connections
MAX_KEEPALIVE_CONNECTIONS=20
# Keepalive connection expiry in seconds
KEEPALIVE_EXPIRY=30.0

# Circuit Breaker Configuration (AI Provider Resilience)
# Number of failures before opening circuit
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
# Seconds to wait before attempting recovery
CIRCUIT_BREAKER_TIMEOUT=60

# Context7 Integration (Simplified Documentation Validation)
# Enable Context7 for evidence-based documentation validation using validate_code_against_docs
CONTEXT7_ENABLED=true
# Context7 service URL (Docker service name or localhost)
CONTEXT7_API_URL=http://context7:8080
# Maximum tokens for documentation validation requests
CONTEXT7_MAX_TOKENS=2000
# Cache TTL for documentation lookups in seconds
CONTEXT7_CACHE_TTL=3600

